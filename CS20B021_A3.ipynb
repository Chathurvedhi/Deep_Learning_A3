{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - CS20B021 - CS6910"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 40\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0]) < MAX_LEN and \\\n",
    "        len(p[1]) < MAX_LEN\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('tel_train.csv')\n",
    "valid_data = pd.read_csv('tel_valid.csv')\n",
    "test_data = pd.read_csv('tel_test.csv')\n",
    "\n",
    "# Prepare data in pairs\n",
    "train_pairs = []\n",
    "for line in train_data.values:\n",
    "    train_pairs.append([line[0], line[1]])\n",
    "    \n",
    "valid_pairs = []\n",
    "for line in valid_data.values:\n",
    "    valid_pairs.append([line[0], line[1]])\n",
    "\n",
    "test_pairs = []\n",
    "for line in test_data.values:\n",
    "    test_pairs.append([line[0], line[1]])\n",
    "\n",
    "# Filter pairs with length > MAX_LEN\n",
    "train_pairs = filterPairs(train_pairs)\n",
    "valid_pairs = filterPairs(valid_pairs)\n",
    "test_pairs = filterPairs(test_pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, type):\n",
    "        self.type = type\n",
    "        self.char2index = {}\n",
    "        self.char2count = {}\n",
    "        self.index2char = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_chars = 2  # Count SOS and EOS\n",
    "\n",
    "    def addChar(self, char):\n",
    "        if char not in self.char2index:\n",
    "            self.char2index[char] = self.n_chars\n",
    "            self.char2count[char] = 1\n",
    "            self.index2char[self.n_chars] = char\n",
    "            self.n_chars += 1\n",
    "        else:\n",
    "            self.char2count[char] += 1\n",
    "\n",
    "    def addWord(self, word):\n",
    "        for char in word:\n",
    "            self.addChar(char)\n",
    "\n",
    "input_lang = Lang('input')\n",
    "output_lang = Lang('output')\n",
    "\n",
    "for pair in train_pairs:\n",
    "    input_lang.addWord(pair[0])\n",
    "    output_lang.addWord(pair[1])\n",
    "\n",
    "def indexesFromWord(lang, word):\n",
    "    return [lang.char2index[char] for char in word]\n",
    "\n",
    "def tensorFromWord(lang, word):\n",
    "    indexes = indexesFromWord(lang, word)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorFromPair(pair):\n",
    "    input_tensor = tensorFromWord(input_lang, pair[0])\n",
    "    target_tensor = tensorFromWord(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size = 128, embed_size = 64, num_layers = 1, cell_type = 'gru', dropout = 0.1, bidirectional = False):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Class Variables\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        # Layers and Cells Initialized with parameters\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        if cell_type == 'gru':\n",
    "            self.cell = nn.GRU(input_size = self.embed_size, hidden_size = self.hidden_size, num_layers = self.num_layers, dropout = self.dropout, bidirectional = self.bidirectional)\n",
    "        elif cell_type == 'rnn':\n",
    "            self.cell = nn.RNN(input_size = self.embed_size, hidden_size = self.hidden_size, num_layers = self.num_layers, dropout = self.dropout, bidirectional = self.bidirectional)\n",
    "        elif cell_type == 'lstm':\n",
    "            self.cell = nn.LSTM(input_size = self.embed_size, hidden_size = self.hidden_size, num_layers = self.num_layers, dropout = self.dropout, bidirectional = self.bidirectional)\n",
    "        else:\n",
    "            raise ValueError('Invalid cell type specified')\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "\n",
    "        # Forward pass through the cell\n",
    "        if self.cell_type == 'lstm':\n",
    "            output, (hidden, cell) = self.cell(embedded, (hidden, cell))\n",
    "        else:\n",
    "            output, hidden = self.cell(embedded, hidden)\n",
    "\n",
    "        return output, hidden, cell\n",
    "    \n",
    "    def initHidden(self):\n",
    "        # Initialize hidden state with zeros\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size,hidden_size = 128, embed_size = 64, num_layers = 1, cell_type = 'gru', dropout = 0.1, bidirectional = False):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Class Variables\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        # Layers and Cells Initialized with parameters\n",
    "        self.embedding = nn.Embedding(output_size, embed_size)\n",
    "        if cell_type == 'gru':\n",
    "            self.cell = nn.GRU(input_size = self.embed_size, hidden_size = self.hidden_size, num_layers = self.num_layers, dropout = self.dropout, bidirectional = self.bidirectional)\n",
    "        elif cell_type == 'rnn':\n",
    "            self.cell = nn.RNN(input_size = self.embed_size, hidden_size = self.hidden_size, num_layers = self.num_layers, dropout = self.dropout, bidirectional = self.bidirectional)\n",
    "        elif cell_type == 'lstm':\n",
    "            self.cell = nn.LSTM(input_size = self.embed_size, hidden_size = self.hidden_size, num_layers = self.num_layers, dropout = self.dropout, bidirectional = self.bidirectional)\n",
    "        else:\n",
    "            raise ValueError('Invalid cell type specified')\n",
    "        self.out = nn.Linear(self.hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "\n",
    "        # Forward pass through the cell\n",
    "        if self.cell_type == 'lstm':\n",
    "            output, (hidden, cell) = self.cell(output, (hidden, cell))\n",
    "        else:\n",
    "            output, hidden = self.cell(output, hidden)\n",
    "\n",
    "        # Output with softmax\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden, cell\n",
    "\n",
    "    def initHidden(self):\n",
    "        # Initialize hidden state with zeros\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Decoder "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence to Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq():\n",
    "    def __init__(self, hidden_size = 128, embed_size = 64, num_layers = 1, cell_type = 'gru', dropout = 0.1, bidirectional = False, optimizer = 'sgd', lr = 0.01):\n",
    "        \n",
    "        # Class Variables\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.optimizer = optimizer\n",
    "        self.lr = lr\n",
    "\n",
    "        # Initialize Encoder and Decoder\n",
    "        self.encoder = Encoder(input_lang.n_chars, hidden_size, embed_size, num_layers, cell_type, dropout, bidirectional).to(device)\n",
    "        self.decoder = Decoder(output_lang.n_chars, hidden_size, embed_size, num_layers, cell_type, dropout, bidirectional).to(device)\n",
    "\n",
    "        # Initialize Optimizer\n",
    "        if optimizer == 'sgd':\n",
    "            self.encoder_optimizer = optim.SGD(self.encoder.parameters(), lr = self.lr)\n",
    "            self.decoder_optimizer = optim.SGD(self.decoder.parameters(), lr = self.lr)\n",
    "        elif optimizer == 'adam':\n",
    "            self.encoder_optimizer = optim.Adam(self.encoder.parameters(), lr = self.lr)\n",
    "            self.decoder_optimizer = optim.Adam(self.decoder.parameters(), lr = self.lr)\n",
    "        else:\n",
    "            raise ValueError('Invalid optimizer specified')\n",
    "        \n",
    "        # Initialize Criterion\n",
    "        self.criterion = nn.NLLLoss()\n",
    "\n",
    "    def train(self, input_tensor, target_tensor):\n",
    "\n",
    "        # Initialize Encoder Hidden State\n",
    "        encoder_hidden = self.encoder.initHidden()\n",
    "        encoder_cell = self.encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(MAX_LEN, self.encoder.hidden_size, device=device)\n",
    "\n",
    "        # Zero Gradients\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Get input and target length\n",
    "        input_length = input_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "\n",
    "        # Initialize Loss\n",
    "        loss = 0\n",
    "\n",
    "        # Forward pass through the encoder\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden, encoder_cell = self.encoder(input_tensor[ei], encoder_hidden, encoder_cell)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        # Initialize Decoder Hidden State\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\n",
    "\n",
    "        # Use Teacher Forcing\n",
    "        use_teacher_forcing = True if random.random() < 0.5 else False\n",
    "        \n",
    "        # Forward pass through the decoder\n",
    "        if use_teacher_forcing:\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_cell = self.decoder(decoder_input, decoder_hidden, decoder_cell)\n",
    "                loss += self.criterion(decoder_output, target_tensor[di])\n",
    "                decoder_input = target_tensor[di]\n",
    "        else:\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_cell = self.decoder(decoder_input, decoder_hidden, decoder_cell)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                loss += self.criterion(decoder_output, target_tensor[di])\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "        # Backpropagate Loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Parameters\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "\n",
    "        return loss.item() / target_length\n",
    "    \n",
    "    def evaluate(self, word: str):\n",
    "        with torch.no_grad():\n",
    "            input_tensor = tensorFromWord(input_lang, word)\n",
    "            input_length = input_tensor.size()[0]\n",
    "            encoder_hidden = self.encoder.initHidden()\n",
    "            encoder_cell = self.encoder.initHidden()\n",
    "\n",
    "            encoder_outputs = torch.zeros(MAX_LEN, self.hidden_size, device=device)\n",
    "\n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden, encoder_cell = self.encoder(input_tensor[ei],\n",
    "                                                        encoder_hidden, encoder_cell)\n",
    "                encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "            decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "            decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\n",
    "\n",
    "            decoded_words = []\n",
    "\n",
    "            for di in range(MAX_LEN):\n",
    "                decoder_output, decoder_hidden, decoder_cell = self.decoder(\n",
    "                    decoder_input, decoder_hidden, decoder_cell)\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                if topi.item() == EOS_token:\n",
    "                    decoded_words.append('<EOS>')\n",
    "                    break\n",
    "                else:\n",
    "                    decoded_words.append(output_lang.index2letter[topi.item()])\n",
    "\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "            return decoded_words\n",
    "        \n",
    "    def accuracy(self, pairs):\n",
    "        \n",
    "        # Returns the accuracy of the model on the given pairs\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for pair in pairs:\n",
    "            output_words = self.evaluate(pair[0])\n",
    "            output_sentence = ''.join(output_words)\n",
    "            if output_sentence == pair[1]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        return correct / total\n",
    "        \n",
    "    def trainEpoch(self, epochs = 5, Log = False):\n",
    "        \n",
    "        # Initializations\n",
    "        start = time.time()\n",
    "        print_loss_total = 0  # Reset every 1000 steps\n",
    "        prev_train_acc = 0\n",
    "        prev_val_acc = 0\n",
    "        log_loss_total = 0\n",
    "\n",
    "        # Train for given number of epochs\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            print('Epoch: ', epoch)\n",
    "\n",
    "            # Get Tensor Pairs\n",
    "            training_pairs = [tensorFromPair(pair) for pair in train_pairs]\n",
    "\n",
    "            # Train for one epoch\n",
    "            for i in range(1, len(training_pairs) + 1):\n",
    "                training_pair = training_pairs[i - 1]\n",
    "                input_tensor = training_pair[0]\n",
    "                target_tensor = training_pair[1]\n",
    "\n",
    "                loss = self.train(input_tensor, target_tensor)\n",
    "                print_loss_total += loss\n",
    "                log_loss_total += loss\n",
    "\n",
    "                # Print Progress\n",
    "                if i % 1000 == 0:\n",
    "                    temp = len(train_pairs)\n",
    "                    print_loss_avg = print_loss_total / 1000\n",
    "                    print_loss_total = 0\n",
    "                    print('%s (%d %d%%) %.4f' % (timeSince(start, i / len(train_pairs)),\n",
    "                                                i, i /  len(train_pairs) * 100, print_loss_avg))\n",
    "\n",
    "            # Training Loss\n",
    "            train_loss = log_loss_total / len(train_pairs)\n",
    "\n",
    "            # Train Accuracy\n",
    "            train_acc = self.accuracy(train_pairs)\n",
    "            print('Train Accuracy: ', train_acc)\n",
    "\n",
    "            # Validation Accuracy\n",
    "            val_acc = self.accuracy(valid_pairs)\n",
    "            print('Validation Accuracy: ', val_acc)\n",
    "\n",
    "            # Check to end\n",
    "            if val_acc < prev_val_acc or train_acc < prev_train_acc:\n",
    "                break\n",
    "                \n",
    "            # Update previous accuracy\n",
    "            prev_train_acc = train_acc\n",
    "            prev_val_acc = val_acc\n",
    "\n",
    "            # Log to wandb\n",
    "            if Log:\n",
    "                wandb.log({\n",
    "                            \"train_loss\": train_loss,\n",
    "                            \"train_acc\": train_acc, \n",
    "                            \"val_acc\": val_acc,\n",
    "                            \"epoch\": epoch\n",
    "                            })\n",
    "                \n",
    "        if val_acc > 0.4:\n",
    "            torch.save(self.encoder.state_dict(), 'encoder.pth{}|{}|{}|{}|{}|{}|{}|{}',format(epochs, self.hidden_size, self.embed_size, self.cell_type, self.num_layers, self.dropout, self.optimizer, self.lr))\n",
    "            torch.save(self.decoder.state_dict(), 'decoder.pth{}|{}|{}|{}|{}|{}|{}|{}',format(epochs, self.hidden_size, self.embed_size, self.cell_type, self.num_layers, self.dropout, self.optimizer, self.lr))\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_acc = self.accuracy(test_pairs)\n",
    "        #print('Test Accuracy: ', test_acc)\n",
    "\n",
    "        # Log to wandb\n",
    "        if Log:\n",
    "            wandb.log({\"test_acc\": test_acc})\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yolo/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "0m 20s (- 16m 57s) (1000 1%) 2.8111\n",
      "0m 37s (- 15m 16s) (2000 3%) 2.7337\n",
      "0m 50s (- 13m 23s) (3000 5%) 2.7473\n",
      "1m 3s (- 12m 23s) (4000 7%) 2.7298\n",
      "1m 15s (- 11m 39s) (5000 9%) 2.6981\n",
      "1m 28s (- 11m 9s) (6000 11%) 2.6325\n",
      "1m 42s (- 10m 46s) (7000 13%) 2.5392\n",
      "1m 57s (- 10m 33s) (8000 15%) 2.3789\n",
      "2m 11s (- 10m 17s) (9000 17%) 2.2601\n",
      "2m 27s (- 10m 6s) (10000 19%) 2.1766\n",
      "2m 42s (- 9m 53s) (11000 21%) 2.0772\n",
      "2m 58s (- 9m 41s) (12000 23%) 1.9625\n",
      "3m 13s (- 9m 28s) (13000 25%) 1.8942\n",
      "3m 28s (- 9m 14s) (14000 27%) 1.8462\n",
      "3m 44s (- 9m 1s) (15000 29%) 1.7696\n",
      "3m 59s (- 8m 47s) (16000 31%) 1.6764\n",
      "4m 15s (- 8m 33s) (17000 33%) 1.6322\n",
      "4m 30s (- 8m 19s) (18000 35%) 1.5923\n",
      "4m 46s (- 8m 6s) (19000 37%) 1.5673\n",
      "5m 2s (- 7m 51s) (20000 39%) 1.5151\n",
      "5m 17s (- 7m 36s) (21000 41%) 1.4549\n",
      "5m 32s (- 7m 21s) (22000 42%) 1.4571\n",
      "5m 48s (- 7m 7s) (23000 44%) 1.4097\n",
      "6m 4s (- 6m 52s) (24000 46%) 1.3755\n",
      "6m 19s (- 6m 38s) (25000 48%) 1.3399\n",
      "6m 36s (- 6m 23s) (26000 50%) 1.3554\n",
      "6m 52s (- 6m 9s) (27000 52%) 1.2831\n",
      "7m 7s (- 5m 54s) (28000 54%) 1.3100\n",
      "7m 23s (- 5m 39s) (29000 56%) 1.2566\n",
      "7m 39s (- 5m 24s) (30000 58%) 1.2379\n",
      "7m 54s (- 5m 9s) (31000 60%) 1.2401\n",
      "8m 10s (- 4m 54s) (32000 62%) 1.2204\n",
      "8m 25s (- 4m 38s) (33000 64%) 1.1802\n",
      "8m 41s (- 4m 23s) (34000 66%) 1.2005\n",
      "8m 56s (- 4m 8s) (35000 68%) 1.1396\n",
      "9m 11s (- 3m 52s) (36000 70%) 1.1230\n",
      "9m 26s (- 3m 37s) (37000 72%) 1.0934\n",
      "9m 42s (- 3m 22s) (38000 74%) 1.1163\n",
      "9m 57s (- 3m 6s) (39000 76%) 1.0853\n",
      "10m 12s (- 2m 51s) (40000 78%) 1.0527\n",
      "10m 28s (- 2m 36s) (41000 80%) 1.0551\n",
      "10m 43s (- 2m 20s) (42000 82%) 1.0765\n",
      "10m 59s (- 2m 5s) (43000 83%) 1.0037\n",
      "11m 15s (- 1m 50s) (44000 85%) 1.0724\n",
      "11m 31s (- 1m 35s) (45000 87%) 1.0175\n",
      "11m 46s (- 1m 19s) (46000 89%) 1.0384\n",
      "12m 2s (- 1m 4s) (47000 91%) 0.9941\n",
      "12m 18s (- 0m 49s) (48000 93%) 1.0398\n",
      "12m 33s (- 0m 33s) (49000 95%) 0.9796\n",
      "12m 49s (- 0m 18s) (50000 97%) 0.9793\n",
      "13m 5s (- 0m 3s) (51000 99%) 1.0029\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Seq2Seq' object has no attribute 'input_lang'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m Seq2Seq(hidden_size \u001b[39m=\u001b[39m \u001b[39m256\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mtrainEpoch(epochs \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[37], line 170\u001b[0m, in \u001b[0;36mSeq2Seq.trainEpoch\u001b[0;34m(self, epochs, Log)\u001b[0m\n\u001b[1;32m    167\u001b[0m train_loss \u001b[39m=\u001b[39m log_loss_total \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_pairs)\n\u001b[1;32m    169\u001b[0m \u001b[39m# Train Accuracy\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m train_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccuracy(train_pairs)\n\u001b[1;32m    171\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Accuracy: \u001b[39m\u001b[39m'\u001b[39m, train_acc)\n\u001b[1;32m    173\u001b[0m \u001b[39m# Validation Accuracy\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[37], line 125\u001b[0m, in \u001b[0;36mSeq2Seq.accuracy\u001b[0;34m(self, pairs)\u001b[0m\n\u001b[1;32m    123\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m pairs:\n\u001b[0;32m--> 125\u001b[0m     output_words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(pair[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    126\u001b[0m     output_sentence \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(output_words)\n\u001b[1;32m    127\u001b[0m     \u001b[39mif\u001b[39;00m output_sentence \u001b[39m==\u001b[39m pair[\u001b[39m1\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[37], line 87\u001b[0m, in \u001b[0;36mSeq2Seq.evaluate\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, word: \u001b[39mstr\u001b[39m):\n\u001b[1;32m     86\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 87\u001b[0m         input_tensor \u001b[39m=\u001b[39m tensorFromWord(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_lang, word)\n\u001b[1;32m     88\u001b[0m         input_length \u001b[39m=\u001b[39m input_tensor\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m]\n\u001b[1;32m     89\u001b[0m         encoder_hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39minitHidden()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Seq2Seq' object has no attribute 'input_lang'"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(hidden_size = 256)\n",
    "model.trainEpoch(epochs = 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'val_acc',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'hidden_size': {\n",
    "            'values': [128, 256, 512]\n",
    "        },\n",
    "        'embed_size': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "        'num_layers': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['gru', 'rnn', 'lstm']\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.1, 0.2, 0.3]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['sgd', 'adam']\n",
    "        },\n",
    "        'lr': {\n",
    "            'values': [0.01, 0.001, 0.0001]\n",
    "        },\n",
    "        'epoch': {\n",
    "            'values': [5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"CS20B021_A3\")\n",
    "\n",
    "def train_sweep_run():\n",
    "    run = wandb.init()\n",
    "    config = wandb.config\n",
    "    run.name = \"epoch:{}|hid:{}|embed:{}|cell:{}|nlayer:{}|drop:{}|opt:{}|lr:{}\".format(config.epoch, config.hidden_size, config.embed_size, config.cell_type, config.num_layers, config.dropout, config.optimizer, config.lr)\n",
    "\n",
    "    model = Seq2Seq(hidden_size = config.hidden_size, embed_size = config.embed_size, num_layers = config.num_layers, cell_type = config.cell_type, dropout = config.dropout, optimizer = config.optimizer, lr = config.lr)\n",
    "    model.trainEpoch(epochs = config.epoch, Log = True)\n",
    "    run.finish()\n",
    "\n",
    "wandb.agent(sweep_id, train_sweep_run, count = 10, project=\"CS20B021_A3\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
